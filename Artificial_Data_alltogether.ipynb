{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we reproduce the experimental analysis on artificial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import necessary libraries and define functions for our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scheduling_functions import *\n",
    "from scheduling_algorithms import *\n",
    "from numpy import std\n",
    "import sys\n",
    "import copy\n",
    "from random import sample, randint, seed, random\n",
    "from math import isclose, ceil, floor, e, sqrt\n",
    "from statistics import mean\n",
    "from decimal import *\n",
    "from fractions import *\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a bounded random walk:\n",
    "\n",
    "def random_walk_creation(num_jobs, step_size, random_seed, m, M):\n",
    "    seed(random_seed)\n",
    "\n",
    "    ws = [0]*num_jobs\n",
    "    ws[0] = randint(m,M)\n",
    "    steps = [randint(-step_size,step_size) for i in range(1,num_jobs)]\n",
    "    for i in range(1, num_jobs):\n",
    "        ws[i] = ws[i-1] + steps[i-1]\n",
    "        ws[i] = min(ws[i], M)\n",
    "        ws[i] = max(ws[i], m)\n",
    "    return ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a job instance given a list of weights and T\n",
    "\n",
    "def job_instance_creation(ws, T):\n",
    "    # dictionary: key --> job id\n",
    "    #            value --> (weight, release time , deadline)\n",
    "    J = {}\n",
    "    job_id = 1\n",
    "    i = 0\n",
    "    for job_weight in ws:\n",
    "        J[job_id] = (job_weight , i, i+T)\n",
    "        i+=1\n",
    "        job_id+=1\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the energy ratio AVR_energy/Optimal_energy\n",
    "\n",
    "def AVR_energy_ratio(_J, alpha):\n",
    "    \n",
    "    J = copy.deepcopy(_J)\n",
    "    #speed list of average rate\n",
    "    AVR_speed_list = Avg_rate(J)\n",
    "    #energy consumption of AVR\n",
    "    energy_AVR = compute_energy(AVR_speed_list, alpha)\n",
    "    \n",
    "    J = copy.deepcopy(_J)\n",
    "    #speed list of the optimal schedule\n",
    "    optimal_alg_speed_list, _ = Optimal_Alg(J)\n",
    "    #energy consumption of the optimal schedule\n",
    "    energy_optimal = compute_energy(optimal_alg_speed_list, alpha)  \n",
    "    \n",
    "    return float(energy_AVR)/energy_optimal    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the energy ratio OA_energy/Optimal_energy\n",
    "\n",
    "def OA_energy_ratio(_J, alpha):\n",
    "    \n",
    "    J = copy.deepcopy(_J)\n",
    "    #speed list of Optimal Available\n",
    "    OA_speed_list = OptimalOnline(J)\n",
    "    #energy consumption of Optimal Available\n",
    "    energy_OA = sum([s**alpha for s in OA_speed_list])\n",
    "    \n",
    "    J = copy.deepcopy(_J)\n",
    "    #speed list of the optimal schedule\n",
    "    optimal_alg_speed_list, _ = Optimal_Alg(J)\n",
    "    #energy consumption of the optimal schedule\n",
    "    energy_optimal = compute_energy(optimal_alg_speed_list, alpha)    \n",
    "   \n",
    "    return float(energy_OA)/energy_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the energy ratio BKP_energy/Optimal_energy\n",
    "\n",
    "def BKP_energy_ratio(_J, granularity, alpha):\n",
    "    \n",
    "    J = copy.deepcopy(_J)\n",
    "    #energy consumption of the BKP algorithm\n",
    "    energy_BKP = BKP_alg(J, granularity, alpha)\n",
    "\n",
    "    J = copy.deepcopy(_J)\n",
    "    #speed list of the optimal schedule\n",
    "    optimal_alg_speed_list, _ = Optimal_Alg(J)\n",
    "    #energy consumption of the optimal schedule\n",
    "    energy_optimal = compute_energy(optimal_alg_speed_list, alpha)  \n",
    "    \n",
    "    return float(energy_BKP)/energy_optimal    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the energy ratio LAS_energy/Optimal_energy\n",
    "\n",
    "def LAS_energy_ratio(_J_true, _J_pred, epsilon, alpha):\n",
    "    \n",
    "    #compute speedlist returned by LAS\n",
    "    J_true = copy.deepcopy(_J_true)\n",
    "    J_pred = copy.deepcopy(_J_pred)\n",
    "    online_alg_with_predictions_speed_list = Alg_with_Predictions(J_pred, J_true, epsilon)\n",
    "    \n",
    "    #compute speedlist of the optimal schedule of the true instance\n",
    "    J_true = copy.deepcopy(_J_true)\n",
    "    J_pred = copy.deepcopy(_J_pred)\n",
    "    optimal_alg_speed_list, _ = Optimal_Alg(J_true)\n",
    "    \n",
    "    #energy computation\n",
    "    energy_online_alg_with_predictions = compute_energy(online_alg_with_predictions_speed_list, alpha)\n",
    "    energy_optimal = compute_energy(optimal_alg_speed_list, alpha)\n",
    "    \n",
    "    return float(energy_online_alg_with_predictions)/energy_optimal    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we set the parameters of the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance length and T\n",
    "num_jobs = 200\n",
    "T = 20\n",
    "\n",
    "num_of_experiments = 5\n",
    "\n",
    "\n",
    "step_size = 5\n",
    "M = 80\n",
    "m = 20\n",
    "\n",
    "# alpha parameter of the energy consumption\n",
    "alpha = 3\n",
    "\n",
    "# time granularity for BKP algorithm\n",
    "BKP_granularity = 0.25\n",
    "\n",
    "# robustness parameters epsilon which will be tested\n",
    "epsilons=[Fraction(1,100), Fraction(5,100), Fraction(10,100), Fraction(15,100), Fraction(20,100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to increase reproducibility we perform experiments on the same set of (random) true instances with fixed seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_true_lst = []\n",
    "w_true_lst = []\n",
    "for j in range(0,num_of_experiments):\n",
    "     #create a random walk\n",
    "    w_true = random_walk_creation(num_jobs, step_size=5, random_seed=j, M= M, m= m)\n",
    "    \n",
    "    w_true_lst.append(w_true)\n",
    "    #job instance creation\n",
    "    J_true = job_instance_creation(w_true, T)\n",
    "    \n",
    "    J_true_lst.append(J_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Algorithms tested\n",
    "\n",
    "(1) Average Rate Heuristic (AVR)\n",
    "\n",
    "(2) Optimal Available (OA)\n",
    "\n",
    "(3) Bansal, Kimbrel and Pruhs algorithm (BKP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVR:  1.2827963027467046\n",
      "Std  0.060146621411726345\n",
      "=====================\n",
      "BKP:  8.158935369920101\n",
      "Std  0.7250266771899275\n",
      "=====================\n",
      "OA:  1.2158973075494246\n",
      "Std  0.07144926173652723\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "y_AVR = []\n",
    "y_BKP = []\n",
    "y_OA = []\n",
    "dummy_y_AVR = []\n",
    "dummy_y_BKP = []\n",
    "dummy_y_OA = []\n",
    "for j in range(0,num_of_experiments):\n",
    "    J_true = J_true_lst[j]\n",
    "    \n",
    "    AVR = AVR_energy_ratio(J_true,alpha)\n",
    "    BKP = BKP_energy_ratio(J_true,BKP_granularity, alpha)\n",
    "    OA = OA_energy_ratio(J_true, alpha)\n",
    "    dummy_y_AVR.append(AVR)\n",
    "    dummy_y_BKP.append(BKP)\n",
    "    dummy_y_OA.append(OA)\n",
    "std_AVR = std(dummy_y_AVR)\n",
    "std_BKP = std(dummy_y_BKP)\n",
    "std_OA  = std(dummy_y_OA)\n",
    "y_AVR.append(mean(dummy_y_AVR))\n",
    "y_BKP.append(mean(dummy_y_BKP))\n",
    "y_OA.append(mean(dummy_y_OA))\n",
    "\n",
    "print(\"AVR: \", y_AVR[-1])\n",
    "print(\"Std \", std_AVR)\n",
    "print(\"=====================\")   \n",
    "print(\"BKP: \", y_BKP[-1])\n",
    "print(\"Std \", std_BKP)\n",
    "print(\"=====================\")\n",
    "print(\"OA: \", y_OA[-1])\n",
    "print(\"Std \", std_OA)\n",
    "print(\"=====================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Accurate predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We create the artificial predictions of our \"Accurate predictor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_pred_lst = []\n",
    "for j in range(0,num_of_experiments):\n",
    "    w_true = w_true_lst[j]\n",
    "    \n",
    "    seed(j)\n",
    "    error = [randint(-step_size, step_size) for _ in range(0,num_jobs)]\n",
    "    \n",
    "    w_pred = list(map(add, w_true, error))\n",
    "    \n",
    "    \n",
    "    #jon instance creation\n",
    "    J_pred = job_instance_creation(w_pred, T)\n",
    "    \n",
    "    J_pred_lst.append(J_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We test the performance of the Learning Augmented Scheduling (LAS) algorithm when combined with an \"Accurate predictor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSILON =  1/100\n",
      "LA scheduling:  1.008797775717588\n",
      "Std of LA scheduling  0.004224472127155453\n",
      "=====================\n",
      "EPSILON =  1/20\n",
      "LA scheduling:  1.008797775717588\n",
      "Std of LA scheduling  0.004224472127155453\n",
      "=====================\n",
      "EPSILON =  1/10\n",
      "LA scheduling:  1.0375354569452877\n",
      "Std of LA scheduling  0.0082099358605688\n",
      "=====================\n",
      "EPSILON =  3/20\n",
      "LA scheduling:  1.0611072203024607\n",
      "Std of LA scheduling  0.012049543589772636\n",
      "=====================\n",
      "EPSILON =  1/5\n",
      "LA scheduling:  1.0877195788197458\n",
      "Std of LA scheduling  0.01610979841702974\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "for epsilon in epsilons:\n",
    "    print(\"EPSILON = \", epsilon)\n",
    "    y_LA_scheduling = []\n",
    "    \n",
    "    dummy_y_LA_schedulling = []\n",
    "    for j in range(0,num_of_experiments):\n",
    "        J_true = J_true_lst[j]\n",
    "        J_pred = J_pred_lst[j]\n",
    "\n",
    "        LA_scheduling = LAS_energy_ratio(J_true, J_pred, epsilon, alpha)\n",
    "\n",
    "        dummy_y_LA_schedulling.append(LA_scheduling)\n",
    "    \n",
    "    y_LA_scheduling.append(mean(dummy_y_LA_schedulling))\n",
    "    std_LA_scheduling = std(dummy_y_LA_schedulling)\n",
    "    \n",
    "    print(\"LA scheduling: \", y_LA_scheduling[-1])\n",
    "    print(\"Std of LA scheduling \", std_LA_scheduling)\n",
    "    print(\"=====================\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Random predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we create the artificial predictions of our \"Random predictor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_pred_lst = []\n",
    "for j in range(0,num_of_experiments):\n",
    "    seed(j)\n",
    "    error = [randint(-step_size, step_size) for _ in range(0,num_jobs)]\n",
    "    \n",
    "    w_pred = [randint(m,M) for _ in range(0,num_jobs)]\n",
    "    \n",
    "    \n",
    "    #jon instance creation\n",
    "    J_pred = job_instance_creation(w_pred, T)\n",
    "    \n",
    "    J_pred_lst.append(J_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We test the performance of the Learning Augmented Scheduling (LAS) algorithm when combined with a \"Random predictor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSILON =  1/100\n",
      "LA scheduling:  1.2272868504934065\n",
      "Std of LA scheduling  0.15257040402039085\n",
      "=====================\n",
      "EPSILON =  1/20\n",
      "LA scheduling:  1.2272868504934065\n",
      "Std of LA scheduling  0.15257040402039085\n",
      "=====================\n",
      "EPSILON =  1/10\n",
      "LA scheduling:  1.2142136836796331\n",
      "Std of LA scheduling  0.09960649189584056\n",
      "=====================\n",
      "EPSILON =  3/20\n",
      "LA scheduling:  1.21758096564505\n",
      "Std of LA scheduling  0.07884581292267899\n",
      "=====================\n",
      "EPSILON =  1/5\n",
      "LA scheduling:  1.2227424844570534\n",
      "Std of LA scheduling  0.06910965561802387\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "for epsilon in epsilons:\n",
    "    print(\"EPSILON = \", epsilon)\n",
    "    y_LA_scheduling = []\n",
    "    \n",
    "    dummy_y_LA_schedulling = []\n",
    "    for j in range(0,num_of_experiments):\n",
    "        J_true = J_true_lst[j]\n",
    "        J_pred = J_pred_lst[j]\n",
    "\n",
    "        LA_scheduling = LAS_energy_ratio(J_true, J_pred, epsilon, alpha)\n",
    "\n",
    "        dummy_y_LA_schedulling.append(LA_scheduling)\n",
    "\n",
    "    y_LA_scheduling.append(mean(dummy_y_LA_schedulling))\n",
    "    std_LA_scheduling = std(dummy_y_LA_schedulling)\n",
    "    \n",
    "    print(\"LA scheduling: \", y_LA_scheduling[-1])\n",
    "    print(\"Std of LA scheduling \", std_LA_scheduling)\n",
    "\n",
    "    print(\"=====================\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misleading predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We create the artificial predictions of our \"Misleading predictor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_pred_lst = []\n",
    "for j in range(0,num_of_experiments):\n",
    "    w_true = w_true_lst[j]\n",
    "    \n",
    "    w_pred = []\n",
    "    for i in range(0,num_jobs):\n",
    "        w_pred.append((M-w_true[i]) + m)\n",
    "    \n",
    "    \n",
    "    #jon instance creation\n",
    "    J_pred = job_instance_creation(w_pred, T)\n",
    "    \n",
    "    J_pred_lst.append(J_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We test the performance of the Learning Augmented Scheduling (LAS) algorithm when combined with a \"Misleading predictor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSILON =  1/100\n",
      "LA scheduling:  1.7664395341654813\n",
      "Std of LA scheduling  0.18229572573459152\n",
      "=====================\n",
      "EPSILON =  1/20\n",
      "LA scheduling:  1.7664395341654813\n",
      "Std of LA scheduling  0.18229572573459152\n",
      "=====================\n",
      "EPSILON =  1/10\n",
      "LA scheduling:  1.7216664219682838\n",
      "Std of LA scheduling  0.1666494939496596\n",
      "=====================\n",
      "EPSILON =  3/20\n",
      "LA scheduling:  1.6865635651495268\n",
      "Std of LA scheduling  0.15017607269079586\n",
      "=====================\n",
      "EPSILON =  1/5\n",
      "LA scheduling:  1.6317485187164829\n",
      "Std of LA scheduling  0.14190036190566915\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "for epsilon in epsilons:\n",
    "    print(\"EPSILON = \", epsilon)\n",
    "    y_LA_scheduling = []\n",
    "    \n",
    "    dummy_y_LA_schedulling = []\n",
    "    for j in range(0,num_of_experiments):\n",
    "        J_true = J_true_lst[j]\n",
    "        J_pred = J_pred_lst[j]\n",
    "\n",
    "        LA_scheduling = LAS_energy_ratio(J_true, J_pred, epsilon, alpha)\n",
    "\n",
    "        dummy_y_LA_schedulling.append(LA_scheduling)\n",
    "\n",
    "    y_LA_scheduling.append(max(dummy_y_LA_schedulling))\n",
    "    std_LA_scheduling = std(dummy_y_LA_schedulling)\n",
    "    \n",
    "    print(\"LA scheduling: \", y_LA_scheduling[-1])\n",
    "    print(\"Std of LA scheduling \", std_LA_scheduling)\n",
    "\n",
    "    print(\"=====================\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
